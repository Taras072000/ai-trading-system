"""
ü§ñ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ AI –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ—Ä: AI Trading System
–î–∞—Ç–∞: 2024
"""

import asyncio
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AIModelsDiagnostics:
    """
    ü§ñ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    1. –ù–∞–ª–∏—á–∏–µ API –∫–ª—é—á–µ–π
    2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
    3. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–æ–≤
    4. –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    """
    
    def __init__(self):
        self.results = {}
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ AI –º–æ–¥–µ–ª–µ–π")
    
    async def run_full_ai_diagnostics(self) -> Dict[str, Any]:
        """
        üöÄ –ü–û–õ–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô
        
        –≠—Ç–∞–ø—ã:
        1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        4. –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        """
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AI –º–æ–¥–µ–ª–µ–π...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'environment_check': {},
            'config_check': {},
            'initialization_check': {},
            'api_test': {},
            'summary': {},
            'recommendations': []
        }
        
        try:
            # –≠—Ç–∞–ø 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
            logger.info("üîë –≠—Ç–∞–ø 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
            results['environment_check'] = await self._check_environment_variables()
            
            # –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            logger.info("‚öôÔ∏è –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
            results['config_check'] = await self._check_configuration_files()
            
            # –≠—Ç–∞–ø 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            logger.info("üîß –≠—Ç–∞–ø 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏...")
            results['initialization_check'] = await self._test_model_initialization()
            
            # –≠—Ç–∞–ø 4: –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            logger.info("üì° –≠—Ç–∞–ø 4: –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã...")
            results['api_test'] = await self._test_api_requests()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            results['summary'] = self._generate_summary(results)
            results['recommendations'] = self._generate_recommendations(results)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
            await self._create_ai_diagnostics_report(results)
            
            logger.info("‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ AI –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ AI –º–æ–¥–µ–ª–µ–π: {e}")
            raise
    
    async def _check_environment_variables(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è AI –º–æ–¥–µ–ª–µ–π"""
        logger.info("üîë –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
        
        required_env_vars = {
            'OPENAI_API_KEY': 'OpenAI (–¥–ª—è trading_ai)',
            'ANTHROPIC_API_KEY': 'Anthropic Claude (–¥–ª—è claude_ai)',
            'GOOGLE_API_KEY': 'Google Gemini (–¥–ª—è gemini_ai)',
            'LAVA_API_KEY': 'Lava AI (–¥–ª—è lava_ai)',
            'LAVA_API_URL': 'Lava AI URL (–¥–ª—è lava_ai)'
        }
        
        env_status = {}
        
        for var_name, description in required_env_vars.items():
            value = os.getenv(var_name)
            if value:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ placeholder
                if value.startswith('sk-') or len(value) > 20:
                    env_status[var_name] = {
                        'status': 'OK',
                        'description': description,
                        'length': len(value),
                        'preview': value[:10] + '...' if len(value) > 10 else value
                    }
                    logger.info(f"‚úÖ {var_name}: OK ({len(value)} —Å–∏–º–≤–æ–ª–æ–≤)")
                else:
                    env_status[var_name] = {
                        'status': 'PLACEHOLDER',
                        'description': description,
                        'value': value,
                        'issue': '–ü–æ—Ö–æ–∂–µ –Ω–∞ placeholder'
                    }
                    logger.warning(f"‚ö†Ô∏è {var_name}: Placeholder –∑–Ω–∞—á–µ–Ω–∏–µ")
            else:
                env_status[var_name] = {
                    'status': 'MISSING',
                    'description': description,
                    'issue': '–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'
                }
                logger.error(f"‚ùå {var_name}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        
        return env_status
    
    async def _check_configuration_files(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        logger.info("‚öôÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        
        config_files = [
            '.env',
            'config.json',
            'ai_config.json'
        ]
        
        config_status = {}
        
        for config_file in config_files:
            if os.path.exists(config_file):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        if config_file.endswith('.json'):
                            content = json.load(f)
                            config_status[config_file] = {
                                'status': 'OK',
                                'size': os.path.getsize(config_file),
                                'keys': list(content.keys()) if isinstance(content, dict) else 'Not a dict'
                            }
                        else:
                            content = f.read()
                            config_status[config_file] = {
                                'status': 'OK',
                                'size': os.path.getsize(config_file),
                                'lines': len(content.splitlines())
                            }
                    logger.info(f"‚úÖ {config_file}: OK")
                except Exception as e:
                    config_status[config_file] = {
                        'status': 'ERROR',
                        'error': str(e)
                    }
                    logger.error(f"‚ùå {config_file}: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è - {e}")
            else:
                config_status[config_file] = {
                    'status': 'MISSING'
                }
                logger.warning(f"‚ö†Ô∏è {config_file}: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        return config_status
    
    async def _test_model_initialization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
        logger.info("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π...")
        
        models_to_test = [
            'trading_ai',
            'lava_ai', 
            'gemini_ai',
            'claude_ai'
        ]
        
        init_results = {}
        
        for model_name in models_to_test:
            try:
                logger.info(f"üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name}...")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
                if model_name == 'trading_ai':
                    result = await self._test_openai_initialization()
                elif model_name == 'lava_ai':
                    result = await self._test_lava_initialization()
                elif model_name == 'gemini_ai':
                    result = await self._test_gemini_initialization()
                elif model_name == 'claude_ai':
                    result = await self._test_claude_initialization()
                else:
                    result = {'status': 'UNKNOWN', 'error': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å'}
                
                init_results[model_name] = result
                
                if result['status'] == 'OK':
                    logger.info(f"‚úÖ {model_name}: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
                else:
                    logger.error(f"‚ùå {model_name}: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                    
            except Exception as e:
                init_results[model_name] = {
                    'status': 'ERROR',
                    'error': str(e)
                }
                logger.error(f"‚ùå {model_name}: –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ - {e}")
        
        return init_results
    
    async def _test_openai_initialization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI"""
        try:
            import openai
            
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
            client = openai.OpenAI(api_key=api_key)
            
            return {
                'status': 'OK',
                'client_type': str(type(client)),
                'api_key_length': len(api_key)
            }
            
        except ImportError:
            return {'status': 'ERROR', 'error': '–ú–æ–¥—É–ª—å openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_lava_initialization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Lava AI"""
        try:
            import aiohttp
            
            api_key = os.getenv('LAVA_API_KEY')
            api_url = os.getenv('LAVA_API_URL')
            
            if not api_key:
                return {'status': 'ERROR', 'error': 'LAVA_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
            
            if not api_url:
                return {'status': 'ERROR', 'error': 'LAVA_API_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
            
            return {
                'status': 'OK',
                'api_key_length': len(api_key),
                'api_url': api_url
            }
            
        except ImportError:
            return {'status': 'ERROR', 'error': '–ú–æ–¥—É–ª—å aiohttp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_gemini_initialization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Google Gemini"""
        try:
            import google.generativeai as genai
            
            api_key = os.getenv('GOOGLE_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'GOOGLE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º API
            genai.configure(api_key=api_key)
            
            return {
                'status': 'OK',
                'api_key_length': len(api_key)
            }
            
        except ImportError:
            return {'status': 'ERROR', 'error': '–ú–æ–¥—É–ª—å google-generativeai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_claude_initialization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Anthropic Claude"""
        try:
            import anthropic
            
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'ANTHROPIC_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
            client = anthropic.Anthropic(api_key=api_key)
            
            return {
                'status': 'OK',
                'client_type': str(type(client)),
                'api_key_length': len(api_key)
            }
            
        except ImportError:
            return {'status': 'ERROR', 'error': '–ú–æ–¥—É–ª—å anthropic –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_api_requests(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API –∑–∞–ø—Ä–æ—Å–æ–≤"""
        logger.info("üì° –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API –∑–∞–ø—Ä–æ—Å–æ–≤...")
        
        api_results = {}
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        test_prompt = "–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ API?"
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
        models = ['trading_ai', 'lava_ai', 'gemini_ai', 'claude_ai']
        
        for model_name in models:
            try:
                logger.info(f"üì° –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API {model_name}...")
                
                if model_name == 'trading_ai':
                    result = await self._test_openai_api(test_prompt)
                elif model_name == 'lava_ai':
                    result = await self._test_lava_api(test_prompt)
                elif model_name == 'gemini_ai':
                    result = await self._test_gemini_api(test_prompt)
                elif model_name == 'claude_ai':
                    result = await self._test_claude_api(test_prompt)
                else:
                    result = {'status': 'SKIPPED', 'reason': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å'}
                
                api_results[model_name] = result
                
                if result['status'] == 'OK':
                    logger.info(f"‚úÖ {model_name}: API —Ä–∞–±–æ—Ç–∞–µ—Ç")
                else:
                    logger.error(f"‚ùå {model_name}: {result.get('error', 'API –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç')}")
                    
            except Exception as e:
                api_results[model_name] = {
                    'status': 'ERROR',
                    'error': str(e)
                }
                logger.error(f"‚ùå {model_name}: –û—à–∏–±–∫–∞ API - {e}")
        
        return api_results
    
    async def _test_openai_api(self, prompt: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI API"""
        try:
            import openai
            
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'API –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}
            
            client = openai.OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10
            )
            
            return {
                'status': 'OK',
                'response': response.choices[0].message.content,
                'model': response.model
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_lava_api(self, prompt: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Lava AI API"""
        try:
            import aiohttp
            
            api_key = os.getenv('LAVA_API_KEY')
            api_url = os.getenv('LAVA_API_URL')
            
            if not api_key or not api_url:
                return {'status': 'ERROR', 'error': 'API –∫–ª—é—á –∏–ª–∏ URL –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}
            
            async with aiohttp.ClientSession() as session:
                headers = {'Authorization': f'Bearer {api_key}'}
                data = {'prompt': prompt, 'max_tokens': 10}
                
                async with session.post(api_url, headers=headers, json=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            'status': 'OK',
                            'response': result.get('response', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞'),
                            'status_code': response.status
                        }
                    else:
                        return {
                            'status': 'ERROR',
                            'error': f'HTTP {response.status}',
                            'status_code': response.status
                        }
                        
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_gemini_api(self, prompt: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Gemini API"""
        try:
            import google.generativeai as genai
            
            api_key = os.getenv('GOOGLE_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'API –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-pro')
            
            response = model.generate_content(prompt)
            
            return {
                'status': 'OK',
                'response': response.text,
                'model': 'gemini-pro'
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    async def _test_claude_api(self, prompt: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Anthropic Claude API"""
        try:
            import anthropic
            
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if not api_key:
                return {'status': 'ERROR', 'error': 'API –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}
            
            client = anthropic.Anthropic(api_key=api_key)
            
            response = client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=10,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return {
                'status': 'OK',
                'response': response.content[0].text,
                'model': response.model
            }
            
        except Exception as e:
            return {'status': 'ERROR', 'error': str(e)}
    
    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        summary = {
            'total_models': 4,
            'env_vars_ok': 0,
            'models_initialized': 0,
            'apis_working': 0,
            'critical_issues': [],
            'warnings': []
        }
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for var, status in results['environment_check'].items():
            if status['status'] == 'OK':
                summary['env_vars_ok'] += 1
            elif status['status'] == 'MISSING':
                summary['critical_issues'].append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {var}")
            elif status['status'] == 'PLACEHOLDER':
                summary['warnings'].append(f"Placeholder –≤ {var}")
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
        for model, status in results['initialization_check'].items():
            if status['status'] == 'OK':
                summary['models_initialized'] += 1
            else:
                summary['critical_issues'].append(f"–ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è {model}")
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º API
        for model, status in results['api_test'].items():
            if status['status'] == 'OK':
                summary['apis_working'] += 1
            else:
                summary['critical_issues'].append(f"API –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç {model}")
        
        return summary
    
    def _generate_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for var, status in results['environment_check'].items():
            if status['status'] == 'MISSING':
                recommendations.append(f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è {var}")
            elif status['status'] == 'PLACEHOLDER':
                recommendations.append(f"–ó–∞–º–µ–Ω–∏—Ç—å placeholder –≤ {var} –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π API –∫–ª—é—á")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
        for model, status in results['initialization_check'].items():
            if status['status'] == 'ERROR' and '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' in status.get('error', ''):
                recommendations.append(f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è {model}")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if not recommendations:
            recommendations.append("–í—Å–µ AI –º–æ–¥–µ–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            recommendations.append("–ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É")
        
        return recommendations
    
    async def _create_ai_diagnostics_report(self, results: Dict[str, Any]):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AI –º–æ–¥–µ–ª–µ–π"""
        report_lines = [
            "=" * 80,
            "ü§ñ –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢: –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô",
            "=" * 80,
            f"üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "üìä –°–í–û–î–ö–ê:",
            "-" * 50,
            f"   –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {results['summary']['total_models']}",
            f"   –ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è OK: {results['summary']['env_vars_ok']}/5",
            f"   –ú–æ–¥–µ–ª–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {results['summary']['models_initialized']}/4",
            f"   API —Ä–∞–±–æ—Ç–∞—é—Ç: {results['summary']['apis_working']}/4",
            "",
            "üîë –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø:",
            "-" * 50
        ]
        
        for var, status in results['environment_check'].items():
            status_icon = "‚úÖ" if status['status'] == 'OK' else "‚ö†Ô∏è" if status['status'] == 'PLACEHOLDER' else "‚ùå"
            report_lines.append(f"   {status_icon} {var}: {status['status']}")
            if 'issue' in status:
                report_lines.append(f"      –ü—Ä–æ–±–ª–µ–º–∞: {status['issue']}")
        
        report_lines.extend([
            "",
            "üîß –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô:",
            "-" * 50
        ])
        
        for model, status in results['initialization_check'].items():
            status_icon = "‚úÖ" if status['status'] == 'OK' else "‚ùå"
            report_lines.append(f"   {status_icon} {model}: {status['status']}")
            if 'error' in status:
                report_lines.append(f"      –û—à–∏–±–∫–∞: {status['error']}")
        
        report_lines.extend([
            "",
            "üì° –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï API:",
            "-" * 50
        ])
        
        for model, status in results['api_test'].items():
            status_icon = "‚úÖ" if status['status'] == 'OK' else "‚ùå"
            report_lines.append(f"   {status_icon} {model}: {status['status']}")
            if status['status'] == 'OK' and 'response' in status:
                report_lines.append(f"      –û—Ç–≤–µ—Ç: {status['response']}")
            elif 'error' in status:
                report_lines.append(f"      –û—à–∏–±–∫–∞: {status['error']}")
        
        report_lines.extend([
            "",
            "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:",
            "-" * 50
        ])
        
        for issue in results['summary']['critical_issues']:
            report_lines.append(f"   ‚Ä¢ {issue}")
        
        if not results['summary']['critical_issues']:
            report_lines.append("   –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        
        report_lines.extend([
            "",
            "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
            "-" * 50
        ])
        
        for rec in results['recommendations']:
            report_lines.append(f"   ‚Ä¢ {rec}")
        
        report_lines.extend([
            "",
            "=" * 80,
            "‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô –ó–ê–í–ï–†–®–ï–ù–ê",
            "=" * 80
        ])
        
        report_content = "\n".join(report_lines)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_filename = f"ai_models_diagnostics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"üìã –°–æ–∑–¥–∞–Ω –æ—Ç—á–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AI –º–æ–¥–µ–ª–µ–π: {report_filename}")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AI –º–æ–¥–µ–ª–µ–π"""
    print("ü§ñ –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AI –º–æ–¥–µ–ª–µ–π...")
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    diagnostics = AIModelsDiagnostics()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    try:
        results = await diagnostics.run_full_ai_diagnostics()
        
        print("\n" + "="*60)
        print("‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê AI –ú–û–î–ï–õ–ï–ô –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("="*60)
        print(f"üîë –ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è OK: {results['summary']['env_vars_ok']}/5")
        print(f"üîß –ú–æ–¥–µ–ª–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {results['summary']['models_initialized']}/4")
        print(f"üì° API —Ä–∞–±–æ—Ç–∞—é—Ç: {results['summary']['apis_working']}/4")
        print("="*60)
        
        if results['summary']['critical_issues']:
            print("\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
            for issue in results['summary']['critical_issues']:
                print(f"   ‚Ä¢ {issue}")
        
        if results['summary']['warnings']:
            print("\n‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø:")
            for warning in results['summary']['warnings']:
                print(f"   ‚Ä¢ {warning}")
        
        if results['recommendations']:
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in results['recommendations']:
                print(f"   ‚Ä¢ {rec}")
        
        print(f"\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: ai_models_diagnostics_*.txt")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())