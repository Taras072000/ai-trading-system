#!/usr/bin/env python3
"""
Reinforcement Learning Winrate Tester
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä –≤–∏–Ω—Ä–µ–π—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–æ–º Mistral
"""

import asyncio
import logging
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import pandas as pd
import numpy as np

from ai_modules.multi_ai_orchestrator import MultiAIOrchestrator
from ai_modules.reinforcement_learning_engine import ReinforcementLearningEngine, ReinforcementConfig
from ai_modules.mistral_server_manager import MistralServerManager
from historical_data_manager import HistoricalDataManager
from data_collector import BinanceDataCollector

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class ReinforcementTestConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"""
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    symbols: List[str]
    start_date: str
    end_date: str
    initial_balance: float = 10000.0
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º
    enable_reinforcement_learning: bool = True
    learning_rate: float = 0.01
    reward_multiplier: float = 1.0
    punishment_multiplier: float = 1.5
    weight_decay: float = 0.001
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_intervals: int = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    trades_per_interval: int = 50  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Mistral
    auto_start_mistral: bool = True
    mistral_model: str = "mistral:latest"
    mistral_timeout: int = 300
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    save_results: bool = True
    results_dir: str = "results/reinforcement_learning"
    session_name: Optional[str] = None

@dataclass
class ReinforcementTradeResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –¥–ª—è RL"""
    symbol: str
    action: str
    entry_price: float
    exit_price: float
    pnl: float
    pnl_percent: float
    confidence: float
    entry_time: datetime
    exit_time: datetime
    duration_minutes: int
    
    # RL —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è
    ai_weights_before: Dict[str, float]
    ai_weights_after: Dict[str, float]
    reward_applied: float
    punishment_applied: float
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    market_conditions: Dict
    reasoning: str

@dataclass
class ReinforcementTestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"""
    config: ReinforcementTestConfig
    trades: List[ReinforcementTradeResult]
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_trades: int
    profitable_trades: int
    losing_trades: int
    win_rate: float
    total_pnl: float
    total_pnl_percent: float
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
    interval_stats: List[Dict]
    
    # RL —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    initial_weights: Dict[str, float]
    final_weights: Dict[str, float]
    weight_evolution: List[Dict]
    learning_progress: Dict
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    start_time: datetime
    end_time: datetime
    duration_seconds: float
    
    # Mistral —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    mistral_server_stats: Dict

class ReinforcementWinrateTester:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä –≤–∏–Ω—Ä–µ–π—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º
    """
    
    def __init__(self, config: ReinforcementTestConfig):
        self.config = config
        self.orchestrator = None
        self.historical_data_manager = None
        self.binance_collector = None
        self.mistral_manager = None
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.trades: List[ReinforcementTradeResult] = []
        self.interval_stats: List[Dict] = []
        self.weight_evolution: List[Dict] = []
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.start_time = None
        self.end_time = None
        
    async def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        try:
            logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ReinforcementWinrateTester...")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mistral —Å–µ—Ä–≤–µ—Ä–∞
            if self.config.auto_start_mistral:
                await self._initialize_mistral_server()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ —Å RL
            await self._initialize_ai_orchestrator()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            await self._initialize_data_managers()
            
            logger.info("‚úÖ ReinforcementWinrateTester –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return False
    
    async def _initialize_mistral_server(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ Mistral —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mistral —Å–µ—Ä–≤–µ—Ä–∞...")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Mistral —Å–µ—Ä–≤–µ—Ä–∞
            from config.config_manager import MistralServerConfig
            mistral_config = MistralServerConfig(
                model_name=self.config.mistral_model,
                timeout=self.config.mistral_timeout
            )
            
            self.mistral_manager = MistralServerManager(mistral_config)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞
            status = self.mistral_manager.get_server_status()
            if not status.get('is_running', False):
                logger.info("üöÄ –ó–∞–ø—É—Å–∫ Mistral —Å–µ—Ä–≤–µ—Ä–∞...")
                success = await self.mistral_manager.start_server()
                if not success:
                    raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å Mistral —Å–µ—Ä–≤–µ—Ä")
                
                # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
                await asyncio.sleep(10)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å
                health = await self.mistral_manager.health_check()
                if not health.get('is_running', False):
                    raise Exception("Mistral —Å–µ—Ä–≤–µ—Ä –Ω–µ –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É –∑–¥–æ—Ä–æ–≤—å—è")
            
            logger.info("‚úÖ Mistral —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Mistral —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            raise
    
    async def _initialize_ai_orchestrator(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π RL"""
        try:
            logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ —Å RL...")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é RL
            rl_config = ReinforcementConfig(
                learning_rate=self.config.learning_rate,
                reward_multiplier=self.config.reward_multiplier,
                punishment_multiplier=self.config.punishment_multiplier,
                weight_decay=self.config.weight_decay
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Å RL
            self.orchestrator = MultiAIOrchestrator(
                backtest_mode=True,
                reinforcement_learning=True
            )
            
            await self.orchestrator.initialize()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞
            initial_weights = self.orchestrator.get_reinforcement_learning_stats()
            self.weight_evolution.append({
                'timestamp': datetime.now(),
                'weights': initial_weights.get('current_weights', {}),
                'trade_count': 0,
                'win_rate': 0.0
            })
            
            logger.info("‚úÖ AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Å RL –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {e}")
            raise
    
    async def _initialize_data_managers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            logger.info("üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
            
            self.historical_data_manager = HistoricalDataManager()
            self.binance_collector = BinanceDataCollector()
            
            logger.info("‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    async def run_reinforcement_learning_test(self) -> ReinforcementTestResult:
        """
        –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º
        """
        try:
            self.start_time = datetime.now()
            logger.info(f"üéØ –ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å RL: {self.start_time}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            await self._load_historical_data()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            intervals = self._create_learning_intervals()
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω—Ç–µ—Ä–≤–∞–ª—É
            for i, interval in enumerate(intervals):
                logger.info(f"üìà –ò–Ω—Ç–µ—Ä–≤–∞–ª {i+1}/{len(intervals)}: {interval['start']} - {interval['end']}")
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ
                interval_result = await self._test_interval(interval, i)
                self.interval_stats.append(interval_result)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —ç–≤–æ–ª—é—Ü–∏—é –≤–µ—Å–æ–≤
                current_stats = self.orchestrator.get_reinforcement_learning_stats()
                self.weight_evolution.append({
                    'timestamp': datetime.now(),
                    'weights': current_stats.get('current_weights', {}),
                    'trade_count': len(self.trades),
                    'win_rate': current_stats.get('win_rate', 0.0),
                    'interval': i + 1
                })
                
                logger.info(f"‚úÖ –ò–Ω—Ç–µ—Ä–≤–∞–ª {i+1} –∑–∞–≤–µ—Ä—à–µ–Ω. –í–∏–Ω—Ä–µ–π—Ç: {interval_result['win_rate']:.2%}")
            
            # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = await self._create_final_result()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if self.config.save_results:
                await self._save_results(result)
            
            self.end_time = datetime.now()
            logger.info(f"üèÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {self.end_time}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å RL: {e}")
            raise
        finally:
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Mistral —Å–µ—Ä–≤–µ—Ä –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–ª–∏
            if self.config.auto_start_mistral and self.mistral_manager:
                self.mistral_manager.stop_server()
    
    async def _load_historical_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            for symbol in self.config.symbols:
                logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}...")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞
                data = await self.historical_data_manager.get_historical_data(
                    symbol=symbol,
                    start_date=self.config.start_date,
                    end_date=self.config.end_date,
                    interval='1h'
                )
                
                if data is None or len(data) == 0:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å Binance
                    logger.info(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ {symbol} —Å Binance...")
                    data = await self.binance_collector.get_historical_klines(
                        symbol=symbol,
                        interval='1h',
                        start_str=self.config.start_date,
                        end_str=self.config.end_date
                    )
                    
                    if data is not None:
                        await self.historical_data_manager.save_historical_data(symbol, data)
                
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data) if data is not None else 0} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def _create_learning_intervals(self) -> List[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            start_date = datetime.strptime(self.config.start_date, '%Y-%m-%d')
            end_date = datetime.strptime(self.config.end_date, '%Y-%m-%d')
            
            total_days = (end_date - start_date).days
            days_per_interval = total_days // self.config.test_intervals
            
            intervals = []
            current_start = start_date
            
            for i in range(self.config.test_intervals):
                current_end = current_start + timedelta(days=days_per_interval)
                if i == self.config.test_intervals - 1:  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
                    current_end = end_date
                
                intervals.append({
                    'start': current_start.strftime('%Y-%m-%d'),
                    'end': current_end.strftime('%Y-%m-%d'),
                    'interval_id': i
                })
                
                current_start = current_end
            
            logger.info(f"üìÖ –°–æ–∑–¥–∞–Ω–æ {len(intervals)} –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return intervals
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤: {e}")
            raise
    
    async def _test_interval(self, interval: Dict, interval_id: int) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞"""
        try:
            interval_trades = []
            interval_start_time = datetime.now()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –¥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            weights_before = self.orchestrator.get_reinforcement_learning_stats().get('current_weights', {})
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            signals = await self._generate_signals_for_interval(interval)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫
            if len(signals) > self.config.trades_per_interval:
                signals = signals[:self.config.trades_per_interval]
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å–∏–≥–Ω–∞–ª
            for signal_data in signals:
                trade_result = await self._process_signal(signal_data, weights_before)
                if trade_result:
                    interval_trades.append(trade_result)
                    self.trades.append(trade_result)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –ø–æ—Å–ª–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            weights_after = self.orchestrator.get_reinforcement_learning_stats().get('current_weights', {})
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            profitable_trades = len([t for t in interval_trades if t.pnl > 0])
            total_pnl = sum(t.pnl for t in interval_trades)
            win_rate = profitable_trades / len(interval_trades) if interval_trades else 0
            
            interval_result = {
                'interval_id': interval_id,
                'start_date': interval['start'],
                'end_date': interval['end'],
                'total_trades': len(interval_trades),
                'profitable_trades': profitable_trades,
                'losing_trades': len(interval_trades) - profitable_trades,
                'win_rate': win_rate,
                'total_pnl': total_pnl,
                'weights_before': weights_before,
                'weights_after': weights_after,
                'duration_seconds': (datetime.now() - interval_start_time).total_seconds()
            }
            
            return interval_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ {interval_id}: {e}")
            raise
    
    async def _generate_signals_for_interval(self, interval: Dict) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞"""
        try:
            signals = []
            
            for symbol in self.config.symbols:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                data = await self.historical_data_manager.get_historical_data(
                    symbol=symbol,
                    start_date=interval['start'],
                    end_date=interval['end'],
                    interval='1h'
                )
                
                if data is None or len(data) < 24:  # –ú–∏–Ω–∏–º—É–º 24 —á–∞—Å–∞ –¥–∞–Ω–Ω—ã—Ö
                    continue
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –∫–∞–∂–¥—ã–µ 4 —á–∞—Å–∞
                for i in range(0, len(data), 4):
                    if i + 24 > len(data):  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 24 —á–∞—Å–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        break
                    
                    current_data = data.iloc[i:i+24]
                    current_price = current_data.iloc[-1]['close']
                    timestamp = current_data.iloc[-1]['timestamp']
                    
                    # –°–æ–∑–¥–∞–µ–º market_data –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    market_data = {
                        'price': current_price,
                        'volume': current_data['volume'].mean(),
                        'high_24h': current_data['high'].max(),
                        'low_24h': current_data['low'].min(),
                        'price_change_24h': ((current_price - current_data.iloc[0]['close']) / current_data.iloc[0]['close']) * 100,
                        'timestamp': timestamp
                    }
                    
                    signals.append({
                        'symbol': symbol,
                        'market_data': market_data,
                        'historical_data': current_data,
                        'timestamp': timestamp
                    })
            
            return signals
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
            return []
    
    async def _process_signal(self, signal_data: Dict, weights_before: Dict) -> Optional[ReinforcementTradeResult]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞"""
        try:
            symbol = signal_data['symbol']
            market_data = signal_data['market_data']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ –æ—Ç AI
            decision = await self.orchestrator.analyze_and_decide(symbol, market_data)
            
            if decision.action == 'HOLD':
                return None
            
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–¥–µ–ª–∫—É
            entry_price = decision.entry_price
            entry_time = datetime.fromtimestamp(market_data['timestamp'] / 1000)
            
            # –°–∏–º—É–ª–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥ (—á–µ—Ä–µ–∑ 4-8 —á–∞—Å–æ–≤)
            exit_hours = np.random.randint(4, 9)
            exit_time = entry_time + timedelta(hours=exit_hours)
            
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ü–µ–Ω—É –≤—ã—Ö–æ–¥–∞ (—Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ ¬±5%)
            price_change = np.random.uniform(-0.05, 0.05)
            if decision.action == 'LONG':
                exit_price = entry_price * (1 + price_change)
                pnl = (exit_price - entry_price) / entry_price
            else:  # SHORT
                exit_price = entry_price * (1 - price_change)
                pnl = (entry_price - exit_price) / entry_price
            
            pnl_absolute = pnl * 1000  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø–æ–∑–∏—Ü–∏—é $1000
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ RL
            self.orchestrator.apply_trade_result(
                symbol=symbol,
                action=decision.action,
                pnl=pnl_absolute,
                confidence=decision.confidence,
                entry_price=entry_price,
                exit_price=exit_price,
                duration_minutes=exit_hours * 60
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            weights_after = self.orchestrator.get_reinforcement_learning_stats().get('current_weights', {})
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏
            trade_result = ReinforcementTradeResult(
                symbol=symbol,
                action=decision.action,
                entry_price=entry_price,
                exit_price=exit_price,
                pnl=pnl_absolute,
                pnl_percent=pnl * 100,
                confidence=decision.confidence,
                entry_time=entry_time,
                exit_time=exit_time,
                duration_minutes=exit_hours * 60,
                ai_weights_before=weights_before.copy(),
                ai_weights_after=weights_after.copy(),
                reward_applied=pnl_absolute if pnl_absolute > 0 else 0,
                punishment_applied=abs(pnl_absolute) if pnl_absolute <= 0 else 0,
                market_conditions=market_data.copy(),
                reasoning=decision.reasoning
            )
            
            return trade_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–∞: {e}")
            return None
    
    async def _create_final_result(self) -> ReinforcementTestResult:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        try:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_trades = len(self.trades)
            profitable_trades = len([t for t in self.trades if t.pnl > 0])
            losing_trades = total_trades - profitable_trades
            win_rate = profitable_trades / total_trades if total_trades > 0 else 0
            total_pnl = sum(t.pnl for t in self.trades)
            total_pnl_percent = (total_pnl / self.config.initial_balance) * 100
            
            # RL —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            initial_weights = self.weight_evolution[0]['weights'] if self.weight_evolution else {}
            final_weights = self.weight_evolution[-1]['weights'] if self.weight_evolution else {}
            
            rl_stats = self.orchestrator.get_reinforcement_learning_stats()
            learning_progress = {
                'total_rewards': sum(t.reward_applied for t in self.trades),
                'total_punishments': sum(t.punishment_applied for t in self.trades),
                'weight_changes': len([w for w in self.weight_evolution if w['weights'] != initial_weights]),
                'performance_improvement': win_rate - (self.interval_stats[0]['win_rate'] if self.interval_stats else 0)
            }
            
            # Mistral —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            mistral_stats = {}
            if self.mistral_manager:
                mistral_stats = self.mistral_manager.get_server_status()
            
            result = ReinforcementTestResult(
                config=self.config,
                trades=self.trades,
                total_trades=total_trades,
                profitable_trades=profitable_trades,
                losing_trades=losing_trades,
                win_rate=win_rate,
                total_pnl=total_pnl,
                total_pnl_percent=total_pnl_percent,
                interval_stats=self.interval_stats,
                initial_weights=initial_weights,
                final_weights=final_weights,
                weight_evolution=self.weight_evolution,
                learning_progress=learning_progress,
                start_time=self.start_time,
                end_time=self.end_time,
                duration_seconds=(self.end_time - self.start_time).total_seconds(),
                mistral_server_stats=mistral_stats
            )
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            raise
    
    async def _save_results(self, result: ReinforcementTestResult):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            import os
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(self.config.results_dir, exist_ok=True)
            
            # –ò–º—è —Ñ–∞–π–ª–∞
            session_name = self.config.session_name or f"rl_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            filename = f"{session_name}.json"
            filepath = os.path.join(self.config.results_dir, filename)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å
            result_dict = asdict(result)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
            def convert_datetime(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                elif isinstance(obj, dict):
                    return {k: convert_datetime(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_datetime(item) for item in obj]
                return obj
            
            result_dict = convert_datetime(result_dict)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ—Å—Å–∏—é RL
            if self.orchestrator:
                self.orchestrator.save_reinforcement_learning_session(session_name)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def main():
    """–ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    config = ReinforcementTestConfig(
        symbols=['BTCUSDT', 'ETHUSDT'],
        start_date='2024-01-01',
        end_date='2024-01-31',
        initial_balance=10000.0,
        test_intervals=5,
        trades_per_interval=20,
        learning_rate=0.01,
        session_name='test_session_btc_eth'
    )
    
    tester = ReinforcementWinrateTester(config)
    
    if await tester.initialize():
        result = await tester.run_reinforcement_learning_test()
        
        print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        print(f"üìä –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {result.total_trades}")
        print(f"‚úÖ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö: {result.profitable_trades}")
        print(f"‚ùå –£–±—ã—Ç–æ—á–Ω—ã—Ö: {result.losing_trades}")
        print(f"üìà –í–∏–Ω—Ä–µ–π—Ç: {result.win_rate:.2%}")
        print(f"üí∞ –û–±—â–∏–π PnL: ${result.total_pnl:.2f} ({result.total_pnl_percent:.2f}%)")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {result.duration_seconds:.0f} —Å–µ–∫—É–Ω–¥")
        
        print(f"\nüß† –≠–≤–æ–ª—é—Ü–∏—è –≤–µ—Å–æ–≤ AI:")
        print(f"üî∏ –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞: {result.initial_weights}")
        print(f"üî∏ –§–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞: {result.final_weights}")

if __name__ == "__main__":
    asyncio.run(main())